{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test FastALPR against our dataset\n",
    "\n",
    "- it has different models for detection and OCR that can be tested.\n",
    "- show number of overall detected plates, and put detections in JSON.\n",
    "- creates a dataset with the detection for fiftyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fast_alpr import ALPR\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "\n",
    "detectors_to_test = [\"yolo-v9-t-384-license-plate-end2end\", \n",
    "                        \"yolo-v9-t-512-license-plate-end2end\", \n",
    "                        \"yolo-v9-t-640-license-plate-end2end\", \n",
    "                        \"yolo-v9-s-608-license-plate-end2end\"]\n",
    "ocrs_to_test = [\"european-plates-mobile-vit-v2-model\", \n",
    "                    \"global-plates-mobile-vit-v2-model\"]\n",
    "\n",
    "detectors_to_test = [\"yolo-v9-t-640-license-plate-end2end\"]\n",
    "ocrs_to_test = [\"cct-s-v1-global-model\"]\n",
    "\n",
    "def alpr_results_to_dicts(results):\n",
    "    return [\n",
    "        {\n",
    "            \"confidence\": r.detection.confidence,\n",
    "            \"bounding_box\": {\n",
    "                \"x1\": r.detection.bounding_box.x1,\n",
    "                \"y1\": r.detection.bounding_box.y1,\n",
    "                \"x2\": r.detection.bounding_box.x2,\n",
    "                \"y2\": r.detection.bounding_box.y2,\n",
    "            },\n",
    "            \"ocr_text\": r.ocr.text,\n",
    "            \"ocr_confidence\": r.ocr.confidence\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    "\n",
    "IMAGE_DIR = \"/home/gfuhr/projects/data/immediate_action/B8A44FB3A1F9__front_cars/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test the best detector, using the global OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for detector in detectors_to_test:\n",
    "    alpr = ALPR(\n",
    "        detector_model=detector,\n",
    "        ocr_model=\"global-plates-mobile-vit-v2-model\",\n",
    "    )\n",
    "\n",
    "    filenames = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.png')]\n",
    "    plates = {}\n",
    "\n",
    "    print(f\"Testing detector {detector} on {len(filenames)} images...\")\n",
    "    n_detected = 0\n",
    "    for filename in tqdm(filenames):\n",
    "        alpr_results = alpr.predict(filename)\n",
    "        if alpr_results is not None and len(alpr_results) > 0:\n",
    "            n_detected += len(alpr_results)\n",
    "            plates[os.path.basename(filename)] = alpr_results_to_dicts(alpr_results)\n",
    "        \n",
    "    print(f\"For detector {detector}, detected {n_detected} plates in {len(filenames)} images.\")\n",
    "    out_filename = f\"fast_alpr_plates_{detector.replace('-license-plate-end2end', '')}.json\"\n",
    "    with open(out_filename, \"w\") as f:\n",
    "        json.dump(plates, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For detector yolo-v9-t-384-license-plate-end2end, detected 159 plates in 186 images.\n",
    "- For detector yolo-v9-t-512-license-plate-end2end, detected 174 plates in 186 images.\n",
    "- For detector yolo-v9-t-640-license-plate-end2end, detected 189 plates in 186 images.\n",
    "- For detector yolo-v9-s-608-license-plate-end2end, detected 184 plates in 186 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a fiftyone dataset to compare detections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import fiftyone as fo\n",
    "import fiftyone.core.labels as fol\n",
    "\n",
    "DATASET_NAME = \"alpr_detection_comparison\"\n",
    "\n",
    "if DATASET_NAME in fo.list_datasets():\n",
    "    fo.delete_dataset(DATASET_NAME)\n",
    "\n",
    "dataset = fo.Dataset(name=DATASET_NAME, persistent=True)\n",
    "\n",
    "for filename in sorted(os.listdir(IMAGE_DIR)):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(IMAGE_DIR, filename)\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "\n",
    "    for detector in detectors_to_test:\n",
    "        detections = []\n",
    "        plate_data_filename = f\"fast_alpr_plates_{detector.replace('-license-plate-end2end', '')}.json\"\n",
    "        with open(plate_data_filename, \"r\") as f:\n",
    "            plate_data = json.load(f)\n",
    "\n",
    "        if filename in plate_data:\n",
    "            with Image.open(img_path) as img:\n",
    "                img_w, img_h = img.size\n",
    "\n",
    "            for det in plate_data[filename]:\n",
    "                bbox = det[\"bounding_box\"]\n",
    "                x = bbox[\"x1\"]\n",
    "                y = bbox[\"y1\"]\n",
    "                w = bbox[\"x2\"] - bbox[\"x1\"]\n",
    "                h = bbox[\"y2\"] - bbox[\"y1\"]\n",
    "\n",
    "                # Normalize bounding box\n",
    "                rel_bbox = [x / img_w, y / img_h, w / img_w, h / img_h]\n",
    "\n",
    "                detection = fol.Detection(\n",
    "                    label=detector,                    \n",
    "                    bounding_box=rel_bbox,\n",
    "                    confidence=det[\"confidence\"]\n",
    "                )\n",
    "                #detection[\"ocr_confidence\"] = det.get(\"ocr_confidence\")\n",
    "                detections.append(detection)\n",
    "\n",
    "            sample[detector] = fol.Detections(detections=detections)\n",
    "\n",
    "    dataset.add_sample(sample)\n",
    "print(f\"Dataset {DATASET_NAME} created with {len(dataset)} samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, using the apparently best detector let's compare OCRs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ocr in ocrs_to_test:\n",
    "\n",
    "    alpr = ALPR(\n",
    "        detector_model=\"yolo-v9-t-640-license-plate-end2end\",\n",
    "        ocr_model=ocr,\n",
    "    )\n",
    "\n",
    "    filenames = [os.path.join(IMAGE_DIR, f) for f in os.listdir(IMAGE_DIR) if f.endswith('.png')]\n",
    "    plates = {}\n",
    "\n",
    "    print(f\"Testing OCR {ocr} on {len(filenames)} images...\")\n",
    "    n_detected = 0\n",
    "    for filename in tqdm(filenames):\n",
    "        alpr_results = alpr.predict(filename)\n",
    "        if alpr_results is not None and len(alpr_results) > 0:\n",
    "            n_detected += len(alpr_results)\n",
    "            plates[os.path.basename(filename)] = alpr_results_to_dicts(alpr_results)\n",
    "        \n",
    "    print(f\"For OCR {ocr}, detected {n_detected} plates in {len(filenames)} images.\")\n",
    "    out_filename = f\"fast_alpr_{ocr.replace('-mobile-vit-v2-model', '')}.json\"\n",
    "    with open(out_filename, \"w\") as f:\n",
    "        json.dump(plates, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a fiftyone dataset to compare OCRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import fiftyone as fo\n",
    "import fiftyone.core.labels as fol\n",
    "\n",
    "DATASET_NAME = \"alpr_ocr_comparison\"\n",
    "\n",
    "if DATASET_NAME in fo.list_datasets():\n",
    "    fo.delete_dataset(DATASET_NAME)\n",
    "\n",
    "ocrs_to_compare = [\"global-plates-mobile-vit-v2-model\", \"cct-s-v1-global-model\"]\n",
    "\n",
    "dataset = fo.Dataset(name=DATASET_NAME, persistent=True)\n",
    "\n",
    "for filename in sorted(os.listdir(IMAGE_DIR)):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(IMAGE_DIR, filename)\n",
    "    sample = fo.Sample(filepath=img_path)\n",
    "\n",
    "    for ocr in ocrs_to_compare:\n",
    "        detections = []\n",
    "        plate_data_filename = f\"fast_alpr_{ocr.replace('-mobile-vit-v2-model', '')}.json\"\n",
    "        with open(plate_data_filename, \"r\") as f:\n",
    "            plate_data = json.load(f)\n",
    "\n",
    "        if filename in plate_data:\n",
    "            with Image.open(img_path) as img:\n",
    "                img_w, img_h = img.size\n",
    "\n",
    "            for det in plate_data[filename]:\n",
    "                bbox = det[\"bounding_box\"]\n",
    "                x = bbox[\"x1\"]\n",
    "                y = bbox[\"y1\"]\n",
    "                w = bbox[\"x2\"] - bbox[\"x1\"]\n",
    "                h = bbox[\"y2\"] - bbox[\"y1\"]\n",
    "\n",
    "                # Normalize bounding box\n",
    "                rel_bbox = [x / img_w, y / img_h, w / img_w, h / img_h]\n",
    "\n",
    "                detection = fol.Detection(\n",
    "                    label=det[\"ocr_text\"],                    \n",
    "                    bounding_box=rel_bbox,\n",
    "                    confidence=det[\"ocr_confidence\"]\n",
    "                )\n",
    "                #detection[\"ocr_confidence\"] = det.get(\"ocr_confidence\")\n",
    "                detections.append(detection)\n",
    "\n",
    "            sample[ocr] = fol.Detections(detections=detections)\n",
    "\n",
    "    dataset.add_sample(sample)\n",
    "print(f\"Dataset {DATASET_NAME} created with {len(dataset)} samples.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ai_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
