{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Clustering people based on appearance (re-id)\n",
    "\n",
    "1. Get a dataset with full frames and crop people and save then.\n",
    "2. Extract embeddings for each people appearence.\n",
    "3. Create a visuzalization in fiftyone so I can cluster and annotate easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATASET_DIR = \"/home/gfuhr/projects/data/immediate_action/people_v1/\"\n",
    "OUTPUT_DIR = \"/home/gfuhr/projects/data/immediate_action/people_v1_cropped/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "dataset_annotations = os.path.join(DATASET_DIR, \"annotations.json\")\n",
    "with open(dataset_annotations, \"r\") as f:\n",
    "    ann = json.load(f)\n",
    "\n",
    "images = {img[\"id\"]: img for img in ann[\"images\"]}\n",
    "anns = ann[\"annotations\"]\n",
    "\n",
    "for a in tqdm(anns):\n",
    "    img_info = images[a[\"image_id\"]]\n",
    "    img_path = os.path.join(DATASET_DIR, img_info[\"file_name\"])\n",
    "    if not os.path.exists(img_path): continue\n",
    "    x, y, w, h = map(int, a[\"bbox\"])\n",
    "    im = Image.open(img_path)\n",
    "    crop = im.crop((x, y, x + w, y + h))\n",
    "    out_path = os.path.join(OUTPUT_DIR, f\"{a['id']}.png\")\n",
    "    crop.save(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import glob\n",
    "\n",
    "dataset_name = \"people_v1_cropped\"\n",
    "if dataset_name in fo.list_datasets():\n",
    "    fo.delete_dataset(dataset_name)\n",
    "dataset = fo.Dataset(dataset_name)\n",
    "image_paths = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"*.png\")))\n",
    "\n",
    "samples = [fo.Sample(filepath=img_path) for img_path in image_paths]\n",
    "dataset.add_samples(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone as fo\n",
    "\n",
    "dataset_embeddings = np.load(\"reid/reid_features_sbs_r101.npz\")\n",
    "\n",
    "dataset = fo.load_dataset(\"people_v1_cropped\")\n",
    "embeddings = []\n",
    "\n",
    "for sample in dataset:\n",
    "    filename = os.path.basename(sample.filepath)\n",
    "    if filename in dataset_embeddings:\n",
    "        # print(dataset_embeddings[filename].shape)\n",
    "        # break\n",
    "        embeddings.append(dataset_embeddings[filename])\n",
    "    else:\n",
    "        print(f\"Warning: {filename} not found in dataset embeddings\")\n",
    "        break\n",
    "        \n",
    "    # else: \n",
    "\n",
    "feature_matrix = np.vstack(embeddings)  # shape: (n_images, 512)\n",
    "print(feature_matrix.shape)\n",
    "\n",
    "\n",
    "results = fob.compute_visualization(\n",
    "    dataset, embeddings=feature_matrix, seed=51, brain_key=\"reid_embeddings_sbs_r101\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ai_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
